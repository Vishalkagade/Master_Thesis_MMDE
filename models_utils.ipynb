{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def activation_func(activation_fn):\n",
    "    '''\n",
    "    Select activation function\n",
    "    Arg(s):\n",
    "        activation_fn : str\n",
    "            name of activation function\n",
    "    '''\n",
    "\n",
    "    if 'linear' in activation_fn:\n",
    "        return None\n",
    "    elif 'leaky_relu' in activation_fn:\n",
    "        return torch.nn.LeakyReLU(negative_slope=0.20, inplace=True)\n",
    "    elif 'relu' in activation_fn:\n",
    "        return torch.nn.ReLU()\n",
    "    elif 'elu' in activation_fn:\n",
    "        return torch.nn.ELU()\n",
    "    elif 'sigmoid' in activation_fn:\n",
    "        return torch.nn.Sigmoid()\n",
    "    else:\n",
    "        raise ValueError('Unsupported activation function: {}'.format(activation_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d(torch.nn.Module):\n",
    "    '''\n",
    "    2D convolution class\n",
    "\n",
    "    Arg(s):\n",
    "        in_channels : int\n",
    "            number of input channels\n",
    "        out_channels : int\n",
    "            number of output channels\n",
    "        kernel_size : int\n",
    "            size of kernel\n",
    "        stride : int\n",
    "            stride of convolution\n",
    "        weight_initializer : str\n",
    "            kaiming_normal, kaiming_uniform, xavier_normal, xavier_uniform\n",
    "        activation_func : func\n",
    "            activation function after convolution\n",
    "        use_batch_norm : bool\n",
    "            if set, then applied batch normalization\n",
    "    '''\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 kernel_size=3,\n",
    "                 stride=1,\n",
    "                 weight_initializer='kaiming_uniform',\n",
    "                 activation_func=torch.nn.LeakyReLU(negative_slope=0.10, inplace=True),\n",
    "                 use_batch_norm=False):\n",
    "        super(Conv2d, self).__init__()\n",
    "\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        padding = kernel_size // 2\n",
    "\n",
    "        self.conv = torch.nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            bias=False)\n",
    "\n",
    "        # Select the type of weight initialization, by default kaiming_uniform\n",
    "        if weight_initializer == 'kaiming_normal':\n",
    "            torch.nn.init.kaiming_normal_(self.conv.weight)\n",
    "        elif weight_initializer == 'xavier_normal':\n",
    "            torch.nn.init.xavier_normal_(self.conv.weight)\n",
    "        elif weight_initializer == 'xavier_uniform':\n",
    "            torch.nn.init.xavier_uniform_(self.conv.weight)\n",
    "\n",
    "        self.activation_func = activation_func\n",
    "\n",
    "        if self.use_batch_norm:\n",
    "            self.batch_norm = torch.nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv = self.conv(x)\n",
    "        conv = self.batch_norm(conv) if self.use_batch_norm else conv\n",
    "\n",
    "        if self.activation_func is not None:\n",
    "            return self.activation_func(conv)\n",
    "        else:\n",
    "            return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransposeConv2d(torch.nn.Module):\n",
    "    '''\n",
    "    Transpose convolution class\n",
    "\n",
    "    Arg(s):\n",
    "        in_channels : int\n",
    "            number of input channels\n",
    "        out_channels : int\n",
    "            number of output channels\n",
    "        kernel_size : int\n",
    "            size of kernel (k x k)\n",
    "        weight_initializer : str\n",
    "            kaiming_normal, kaiming_uniform, xavier_normal, xavier_uniform\n",
    "        activation_func : func\n",
    "            activation function after convolution\n",
    "        use_batch_norm : bool\n",
    "            if set, then applied batch normalization\n",
    "    '''\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 kernel_size=3,\n",
    "                 weight_initializer='kaiming_uniform',\n",
    "                 activation_func=torch.nn.LeakyReLU(negative_slope=0.10, inplace=True),\n",
    "                 use_batch_norm=False):\n",
    "        super(TransposeConv2d, self).__init__()\n",
    "\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        padding = kernel_size // 2\n",
    "\n",
    "        self.deconv = torch.nn.ConvTranspose2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=2,\n",
    "            padding=padding,\n",
    "            output_padding=1,\n",
    "            bias=False)\n",
    "\n",
    "        # Select the type of weight initialization, by default kaiming_uniform\n",
    "        if weight_initializer == 'kaiming_normal':\n",
    "            torch.nn.init.kaiming_normal_(self.conv.weight)\n",
    "        elif weight_initializer == 'xavier_normal':\n",
    "            torch.nn.init.xavier_normal_(self.conv.weight)\n",
    "        elif weight_initializer == 'xavier_uniform':\n",
    "            torch.nn.init.xavier_uniform_(self.conv.weight)\n",
    "\n",
    "        self.activation_func = activation_func\n",
    "\n",
    "        if self.use_batch_norm:\n",
    "            self.batch_norm = torch.nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        deconv = self.deconv(x)\n",
    "        deconv = self.batch_norm(deconv) if self.use_batch_norm else deconv\n",
    "        if self.activation_func is not None:\n",
    "            return self.activation_func(deconv)\n",
    "        else:\n",
    "            return deconv\n",
    "        \n",
    "class FullyConnected(torch.nn.Module):\n",
    "    '''\n",
    "    Fully connected layer\n",
    "\n",
    "    Arg(s):\n",
    "        in_channels : int\n",
    "            number of input neurons\n",
    "        out_channels : int\n",
    "            number of output neurons\n",
    "        dropout_rate : float\n",
    "            probability to use dropout\n",
    "    '''\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_features,\n",
    "                 out_features,\n",
    "                 weight_initializer='kaiming_uniform',\n",
    "                 activation_func=torch.nn.LeakyReLU(negative_slope=0.10, inplace=True),\n",
    "                 dropout_rate=0.00):\n",
    "        super(FullyConnected, self).__init__()\n",
    "\n",
    "        self.fully_connected = torch.nn.Linear(in_features, out_features)\n",
    "\n",
    "        if weight_initializer == 'kaiming_normal':\n",
    "            torch.nn.init.kaiming_normal_(self.fully_connected.weight)\n",
    "        elif weight_initializer == 'xavier_normal':\n",
    "            torch.nn.init.xavier_normal_(self.fully_connected.weight)\n",
    "        elif weight_initializer == 'xavier_uniform':\n",
    "            torch.nn.init.xavier_uniform_(self.fully_connected.weight)\n",
    "\n",
    "        self.activation_func = activation_func\n",
    "\n",
    "        if dropout_rate > 0.00 and dropout_rate <= 1.00:\n",
    "            self.dropout = torch.nn.Dropout(p=dropout_rate)\n",
    "        else:\n",
    "            self.dropout = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        fully_connected = self.fully_connected(x)\n",
    "\n",
    "        if self.activation_func is not None:\n",
    "            fully_connected = self.activation_func(fully_connected)\n",
    "\n",
    "        if self.dropout is not None:\n",
    "            return self.dropout(fully_connected)\n",
    "        else:\n",
    "            return fully_connected\n",
    "class ResNetBlock(torch.nn.Module):\n",
    "    '''\n",
    "    Basic ResNet block class\n",
    "    Arg(s):\n",
    "        in_channels : int\n",
    "            number of input channels\n",
    "        out_channels : int\n",
    "            number of output channels\n",
    "        stride : int\n",
    "            stride of convolution\n",
    "        weight_initializer : str\n",
    "            kaiming_normal, kaiming_uniform, xavier_normal, xavier_uniform\n",
    "        activation_func : func\n",
    "            activation function after convolution\n",
    "        use_batch_norm : bool\n",
    "            if set, then applied batch normalization\n",
    "    '''\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 stride=1,\n",
    "                 weight_initializer='kaiming_uniform',\n",
    "                 activation_func=torch.nn.LeakyReLU(negative_slope=0.10, inplace=True),\n",
    "                 use_batch_norm=False):\n",
    "        super(ResNetBlock, self).__init__()\n",
    "\n",
    "        self.activation_func = activation_func\n",
    "\n",
    "        self.conv1 = Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            weight_initializer=weight_initializer,\n",
    "            activation_func=activation_func,\n",
    "            use_batch_norm=use_batch_norm)\n",
    "\n",
    "        self.conv2 = Conv2d(\n",
    "            out_channels,\n",
    "            out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            weight_initializer=weight_initializer,\n",
    "            activation_func=activation_func,\n",
    "            use_batch_norm=use_batch_norm)\n",
    "\n",
    "        self.projection = Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=1,\n",
    "            stride=stride,\n",
    "            weight_initializer=weight_initializer,\n",
    "            activation_func=None,\n",
    "            use_batch_norm=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Perform 2 convolutions\n",
    "        conv1 = self.conv1(x)\n",
    "        conv2 = self.conv2(conv1)\n",
    "\n",
    "        # Perform projection if (1) shape does not match (2) channels do not match\n",
    "        in_shape = list(x.shape)\n",
    "        out_shape = list(conv2.shape)\n",
    "        if in_shape[2:4] != out_shape[2:4] or in_shape[1] != out_shape[1]:\n",
    "            X = self.projection(x)\n",
    "        else:\n",
    "            X = x\n",
    "\n",
    "        # f(x) + x\n",
    "        return self.activation_func(conv2 + X)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "ten = torch.randn((1,1,4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ten.unsqueeze(0).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 4, 4])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.6770, -0.3093, -1.0020,  1.6975],\n",
       "          [-0.2761, -0.8522,  0.4192, -0.3670],\n",
       "          [-2.2015, -0.1245, -0.0280,  0.6368],\n",
       "          [ 1.2628,  0.4008,  0.5427, -0.2467]]]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1 = Conv2d(in_channels=1,out_channels=16)\n",
    "layer_2 = TransposeConv2d(in_channels=16,out_channels=8)\n",
    "layer_3 = FullyConnected(in_features=8,out_features=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "block1 = ResNetBlock(in_channels=1,out_channels=16)\n",
    "x = block1(ten)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18128029950>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x.squeeze(0)[0].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 4, 4])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = layer_1(test)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 8, 8])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = layer_2(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 8, 2])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = layer_3(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.1746, 0.0000, 0.0000],\n",
       "        [0.4597, 2.2726, 0.0000, 0.6749],\n",
       "        [0.7336, 0.0000, 0.7044, 0.0000],\n",
       "        [0.0250, 0.3271, 1.1977, 0.0000]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten = torch.randn((4,4))\n",
    "x = activation_func('relu')\n",
    "x(ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0924,  0.1746, -0.1188, -0.7212],\n",
       "        [ 0.4597,  2.2726, -0.4107,  0.6749],\n",
       "        [ 0.7336, -0.1322,  0.7044, -0.2247],\n",
       "        [ 0.0250,  0.3271,  1.1977, -0.6648]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = activation_func('elu')\n",
    "x(ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0194,  0.1746, -0.0253, -0.2554],\n",
       "        [ 0.4597,  2.2726, -0.1058,  0.6749],\n",
       "        [ 0.7336, -0.0284,  0.7044, -0.0509],\n",
       "        [ 0.0250,  0.3271,  1.1977, -0.2186]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = activation_func('leaky_relu')\n",
    "x(ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4952, 0.5435, 0.4937, 0.4365],\n",
       "        [0.6130, 0.9066, 0.4736, 0.6626],\n",
       "        [0.6756, 0.4929, 0.6692, 0.4873],\n",
       "        [0.5063, 0.5811, 0.7681, 0.4456]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = activation_func('sigmoid')\n",
    "x(ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4806"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0194-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
